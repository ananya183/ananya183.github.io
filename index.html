<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Rachneet Kaur</title>
  
  <meta name="author" content="Rachneet Kaur">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Rachneet Kaur</name>
              </p>
              <p>I am a PhD student in the Department of Industrial and Enterprise Systems Engineering at UIUC working with <a href="https://ise.illinois.edu/directory/profile/r-sowers">Richard Sowers </a>.
              </p>
              <p>
                At Google I've worked on <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://www.google.com/get/cardboard/jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, and <a href="https://www.youtube.com/watch?v=JSnB06um5r4">Glass</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I did my bachelors at the <a href="http://cs.toronto.edu">University of Toronto</a>.
                I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:kaurrachneet6@gmail.com">Email</a> &nbsp|&nbsp
                <a href="Data/RK_AcademicVersionCV.pdf">CV</a> &nbsp|&nbsp
                <a href="data/JonBarron-bio.txt">Biography</a> &nbsp|&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=yjLgy48AAAAJ">Google Scholar</a> &nbsp|&nbsp
                <a href="https://twitter.com/kaurrachneet6">Twitter</a>&nbsp|&nbsp
                <a href="https://www.linkedin.com/in/rachneet-kaur-a1ba5354/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="Images/RachneetKaur.jpg"><img style="width:70%;max-width:100%" alt="profile photo" src="Images/RachneetKaur.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Highlights and News</heading>
            </td>
            </tr>
            </tbody></table>
        
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:collapse;margin-top:0px;margin-bottom:0px;margin-right:auto;margin-left:auto;cellpadding:0;cellspacing:0;padding-top:0px"><tbody>
          <tr style = "border-spacing:0px;border-collapse:collapse;cellpadding:0;cellspacing:0;padding-top:0px; padding-bottom:0px">
            <td style="padding-top:10px;padding-bottom:10px;padding-left:20px;padding-right:20px;width:15%;max-width:50%;height:2%;max-height:2%;vertical-align:center"><strong>Aug 2019</strong></td>
            <td width="85%" valign="center">
              Awarded the <a href = "https://grainger.illinois.edu/alumni/hall-of-fame/9647">Willian A. Chittenden II</a> Graduate Fellowship for academic year 2019-2020
            </td>
            </td>
            </tr>
        
        <tr style = "border-spacing:0px;border-collapse:collapse;cellpadding:0;cellspacing:0;padding-top:0px; padding-bottom:0px">
            <td style="padding-top:10px;padding-bottom:10px;padding-left:20px;padding-right:20px;width:15%;max-width:50%;height:2%;max-height:2%;vertical-align:center"><strong>Aug 2018</strong></td>
            <td width="85%" valign="center">
              Awarded the <a href = "https://grainger.illinois.edu/alumni/hall-of-fame/9647">Willian A. Chittenden II</a> Graduate Fellowship for academic year 2018-2019
            </td>
            </td>
            </tr>
          <tr>
              <td style="padding-top:10px;padding-bottom:10px;padding-left:20px;padding-right:20px;width:15%;max-width:50%;height:2%;max-height:2%;vertical-align:center"><strong>Mar 2018</strong></td>
            <td width="85%" valign="center">
              Selected as the recepient of the 2018 <a href = "https://math.illinois.edu/research/igl">Illinois Geometry Lab</a> Research Award 
            </td>
            </tr>
        
          <tr>
              <td style="padding-top:10px;padding-bottom:10px;padding-left:20px;padding-right:20px;width:15%;max-width:50%;height:2%;max-height:2%;vertical-align:center"><strong>Dec 2017</strong></td>
            <td width="85%" valign="center">
              Selected as the 1<sup>st</sup> runner up for <a href = "https://ise.illinois.edu/mottier/index.html">Mottier Innovation Challenge in Systems Engineering Award</a> 
            </td>
            </tr>
          <tr>
              <td style="padding-top:10px;padding-bottom:10px;padding-left:20px;padding-right:20px;width:15%;max-width:50%;height:5%;max-height:5%;vertical-align:center"><strong>Mar 2015</strong></td>
            <td width="85%" valign="center">
              Awarded the <a href = "https://www.inde.campusfrance.org/charpak-lab-scholarship">Charpak Research Intern Scholarship</a> for summer of 2015
            </td>
            </tr>
          <tr>
              <td style="padding-top:10px;padding-bottom:10px;padding-left:20px;padding-right:20px;width:15%;max-width:50%;height:5%;max-height:5%;vertical-align:center"><strong>Dec 2012</strong></td>
            <td width="85%" valign="center">
              Won the <a href = "http://ramanujancompetition.du.ac.in/">Legacy of Srinivasa Ramanujan Coding Competition</a> 
              <br>
              (Awarded at the International conference on Legacy of Srinivasa Ramanujan, 2012)
            </td>
            </tr>
        </tbody></table>
  

        
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>About Me</heading>
            </td>
            </tr>
            </tbody></table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
              <p>
                I'm interested in computer vision, machine learning, optimization, and image processing.
                Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images.
                Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="dualrefl_stop()" onmouseover="dualrefl_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='projects/Accelerometer_EMBC2020_image' width="160">
              <script type="text/javascript">
                function dualrefl_start() {
                  document.getElementById('dualrefl_image').style.opacity = "1";
                }

                function dualrefl_stop() {
                  document.getElementById('dualrefl_image').style.opacity = "0";
                }
                dualrefl_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9175871">
                <papertitle>Exploration of Machine Learning to Identify Community Dwelling Older Adults with Balance Dysfunction Using Short Duration Accelerometer Data</papertitle>
              </a>
              <br>
              <a href="https://www.researchgate.net/profile/Yang_Hu143">Yang Hu</a>*,
              <a href="https://www.researchgate.net/profile/Alka_Bishnoi">Alka Bishnoi</a>*,
              <strong>Rachneet Kaur</strong>,
              <a href="https://ise.illinois.edu/directory/profile/r-sowers">Richard Sowers</a>,
              <a href="https://ahs.illinois.edu/hernandez">Manuel Hernandez</a>
              <br>
              42<sup>nd</sup> Annual International Conference of the IEEE Engineering in Medicine & Biology Society <em>(EMBC)</em>, 2020  
              <br>
              <a href="https://kaurrachneet6.github.io/projects/accelerometer_balance">Project page</a> |
              <a href="https://ieeexplore.ieee.org/document/9175871">Paper</a> |
              <a href="projects/EMBC2020_BF_ML_slides_pdf.pdf">Slides</a> |
              <a href="https://www.youtube.com/watch?v=5nKx9IGo3SA&feature=youtu.be&ab_channel=HernandezLab">Video</a> |
              <a href="./Data/Accelerometer_EMBC2020.txt">Cite</a>
              <p></p>
              <p>
                Examining the feasibility of using wearable sensors, when walking, to identify older adults who have trouble with balance at an early stage.
              </p>
            </td>
          </tr> 

          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='projects/ICdetection_image2.JPG' width="160">
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9175741">
                <papertitle>Automatic Identification of Brain Independent Components in Electroencephalography Data Collected while Standing in a Virtually Immersive Environment - A Deep Learning-Based Approach</papertitle>
              </a>
              <br>
		  <strong>Rachneet Kaur</strong>,
		  <a href="https://www.linkedin.com/in/maxim-korolkov-04004bb5/">Maxim Korolkov</a>,
		  <a href="https://ahs.illinois.edu/hernandez">Manuel Hernandez</a>,
		  <a href="https://ise.illinois.edu/directory/profile/r-sowers">Richard Sowers</a>
              <br>
              42<sup>nd</sup> Annual International Conference of the IEEE Engineering in Medicine & Biology Society <em>(EMBC)</em>, 2020
              <br>
              <a href="https://kaurrachneet6.github.io/projects/ICdetection.html">Project page</a> |
              <a href="https://ieeexplore.ieee.org/document/9175741">Paper</a> |
              <a href="projects/ICdetectionEMBC2020_slides.pdf">Slides</a> |
              <a href="https://www.youtube.com/watch?v=ei4Xs8M8a-w&feature=emb_logo&ab_channel=HernandezLab">Video</a> |
              <a href="./Data/DeepIC_EMBC2020.bib">Cite</a>
              <p></p>
              <p>Automated removal of unwanted artifacts on noisy and visually engaging upright stance Electroencephalography (EEG) data.</p>
            </td>
          </tr> 

          <tr onmouseout="nerfw_stop()" onmouseover="nerfw_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='projects/fitts_explain.png' width="150">
              <script type="text/javascript">
                function nerfw_start() {
                  document.getElementById('nerfw_image').style.opacity = "1";
                }

                function nerfw_stop() {
                  document.getElementById('nerfw_image').style.opacity = "0";
                }
                nerfw_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9035020">
                <papertitle>Using Virtual Reality to Examine the Neural and Physiological Anxiety-Related Responses to Balance-Demanding Target-Reaching Leaning Tasks</papertitle>
              </a>
              <br>
		  <strong>Rachneet Kaur</strong>,
		  <a>Rongyi Sun</a>,
		  <a href="https://neuroscience.illinois.edu/profile/liranz2">Liran Ziegelman</a>,
		  <a href="https://ise.illinois.edu/directory/profile/r-sowers">Richard Sowers</a>,
		  <a href="https://ahs.illinois.edu/hernandez">Manuel Hernandez</a>
              <br>
		    IEEE-RAS 19<sup>th</sup> International Conference on Humanoid Robots <em>(Humanoids)</em>, 2019 
              <br>
             <a href="https://kaurrachneet6.github.io/projects/anxiety_leaning_task.html">Project page</a> |
              <a href="https://ieeexplore.ieee.org/document/9035020">Paper</a> |
              <a href="projects/ICdetectionEMBC2020_slides.pdf">Slides</a> |
              <a href="https://www.youtube.com/watch?v=ei4Xs8M8a-w&feature=emb_logo&ab_channel=HernandezLab">Video</a> |
              <a href="./Data/DeepIC_EMBC2020.bib">Cite</a>
              <p></p>
              <p>Letting NeRF reason about occluders and appearance variation produces photorealistic view synthesis using only unstructured internet photos.</p>
            </td>
          </tr> 

          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='projects/conceptualMap2.JPG' width="160">
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/8983331">
                <papertitle>Using Virtual Reality to Examine the Correlation between Balance Function and Anxiety in Stance</papertitle>
              </a>
              <br>
	  	<a>Rongyi Sun*</a>,
		 <strong>Rachneet Kaur*</strong>,
		  <a href="https://neuroscience.illinois.edu/profile/liranz2">Liran Ziegelman</a>,
		    <a>Shuo Yang</a>,
		  <a href="https://ise.illinois.edu/directory/profile/r-sowers">Richard Sowers</a>,
		  <a href="https://ahs.illinois.edu/hernandez">Manuel Hernandez</a>
              <br>
              IEEE International Conference on Bioinformatics and Biomedicine <em>(BIBM)</em>, 2019
              <br>
             <a href="https://kaurrachneet6.github.io/projects/balance_anxiety_bibm.html">Project page</a> |
              <a href="https://ieeexplore.ieee.org/abstract/document/8983331">Paper</a> |
              <a href="projects/ICdetectionEMBC2020_slides.pdf">Slides</a> |
              <a href="https://www.youtube.com/watch?v=ei4Xs8M8a-w&feature=emb_logo&ab_channel=HernandezLab">Video</a> |
              <a href="./Data/BIBM2019.bib">Cite</a>
              <p></p>
              <p>Examining the interaction between balance function and anxiety via a VR-based experimental setup, designed to simulate stressful environments involving postural threats.</p>
            </td>
          </tr> 

    
          <tr onmouseout="thresh_stop()" onmouseover="thresh_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/thresh_before.jpg' width="160">
              <script type="text/javascript">
                function thresh_start() {
                  document.getElementById('thresh_image').style.opacity = "1";
                }

                function thresh_stop() {
                  document.getElementById('thresh_image').style.opacity = "0";
                }
                thresh_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/8857647">
                <papertitle>Using Virtual Reality to Examine the Neural and Physiological Responses to Height and Perturbations in Quiet Standing</papertitle>
              </a>
              <br>
		<strong>Rachneet Kaur</strong>,
		<a>Rongyi Sun</a>,
		<a href="https://neuroscience.illinois.edu/profile/liranz2">Liran Ziegelman</a>,
		<a href="https://ise.illinois.edu/directory/profile/r-sowers">Richard Sowers</a>,
		<a href="https://ahs.illinois.edu/hernandez">Manuel Hernandez</a>
              <br>
              41<sup>st</sup> Annual International Conference of the IEEE Engineering in Medicine & Biology Society <em>(EMBC)</em>, 2019
              <br>
              <a href="https://github.com/jonbarron/hist_thresh">code</a> / 
              <a href="https://www.youtube.com/watch?v=rHtQQlQo1Q4">video</a> / 
              <a href="data/BarronECCV2020.bib">bibtex</a>
              <br>
              <p></p>
              <p>
              XXX Description XXX
              </p>
            </td>
          </tr>  
    
          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/vase_still.png' width="160">
              <script type="text/javascript">
                function nerf_start() {
                  document.getElementById('nerf_image').style.opacity = "1";
                }

                function nerf_stop() {
                  document.getElementById('nerf_image').style.opacity = "0";
                }
                nerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1812.00546">
                <papertitle>Learning the progression and clinical subtypes of Alzheimer's disease from longitudinal clinical data</papertitle>
              </a>
              <br>
              <a href="https://www.linkedin.com/in/vipulsatone/">Vipul Satone</a>,
              <strong>Rachneet Kaur</strong>,
              <a href="https://scholar.google.com/citations?user=Rr643xYAAAAJ&hl=en">Faraz Faghri</a>,
              <a href="https://scholar.google.com/citations?user=ZjfgPLMAAAAJ&hl=en">Mike A Nalls</a>,
              <a href="https://irp.nih.gov/pi/andrew-singleton">Andrew B Singleton</a>,
	      <a href="https://scholar.google.com/citations?user=2ftJYXMAAAAJ&hl=en">Roy H Campbell</a>
              <br>
              <em>ECCV</em>, 2020 &nbsp <font color="red"><strong>(Oral Presentation, Best Paper Honorable Mention)</strong></font>
              <br>
              <a href="http://www.matthewtancik.com/nerf">project page</a>
              |
              <a href="https://arxiv.org/abs/2003.08934">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=LRAqeM8EjOo&t">talk video</a>
              /
              <a href="https://www.youtube.com/watch?v=JuH79E8rdKc">supp video</a>
              /
              <a href="https://github.com/bmild/nerf">code</a>
              <p></p>
              <p>
              XXX Description XXX
            </td>
          </tr> 
		
		
          <tr onmouseout="uflow_stop()" onmouseover="uflow_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/uflow_before.jpg' width="160">
              <script type="text/javascript">
                function uflow_start() {
                  document.getElementById('uflow_image').style.opacity = "1";
                }

                function uflow_stop() {
                  document.getElementById('uflow_image').style.opacity = "0";
                }
                uflow_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/8512246">
                <papertitle>Virtual Reality, Visual Cliffs, and Movement Disorders</papertitle>
              </a>
              <br>
		<strong>Rachneet Kaur</strong>,
		<a>Xun Lin</a>,
		<a>Alexander Layton</a>,
		<a href="https://ise.illinois.edu/directory/profile/r-sowers">Richard Sowers</a>,
		<a href="https://ahs.illinois.edu/hernandez">Manuel Hernandez</a>
              <br>
              40<sup>th</sup> Annual International Conference of the IEEE Engineering in Medicine & Biology Society <em>(EMBC)</em>, 2018
              <br>
              <a href="https://github.com/google-research/google-research/tree/master/uflow">code</a>
              <br>
              <p></p>
              <p>
               XXX Description XXX
              </p>
            </td>
          </tr>  
   

          <tr onmouseout="porshadmanip_stop()" onmouseover="porshadmanip_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/porshadmanip_before.jpg' width="160">
              <script type="text/javascript">
                function porshadmanip_start() {
                  document.getElementById('porshadmanip_image').style.opacity = "1";
                }

                function porshadmanip_stop() {
                  document.getElementById('porshadmanip_image').style.opacity = "0";
                }
                porshadmanip_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/8857604">
                <papertitle>Exploring Characteristic Features in Gait Patterns for Predicting Multiple Sclerosis</papertitle>
              </a>
              <br>
              <a href="https://people.eecs.berkeley.edu/~cecilia77/">Xuaner (Cecilia) Zhang</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://ai.google/research/people/105312/">Yun-Ta Tsai</a>,
              <a href="https://www.linkedin.com/in/rohit-pandey-bab10b7a/">Rohit Pandey</a>,
              <a href="http://people.csail.mit.edu/xiuming/">Xiuming Zhang</a>,
              <a href="http://graphics.stanford.edu/~renng/">Ren Ng</a>,
              <a href="http://graphics.stanford.edu/~dejacobs/">David E. Jacobs</a>
              <br>
              <em>SIGGRAPH</em>, 2020  
              <br>
              <a href="https://people.eecs.berkeley.edu/~cecilia77/project-pages/portrait">project page</a> / 
              <a href="https://www.youtube.com/watch?v=M_qYTXhzyac">video</a>
              <p></p>
              <p>Networks can be trained to remove shadows cast on human faces and to soften harsh lighting.</p>
            </td>
          </tr>  

          <tr onmouseout="learnaf_stop()" onmouseover="learnaf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='learnaf_image'>
                  <img src='images/learnaf_after.jpg' width="160"></div>
                <img src='images/learnaf_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function learnaf_start() {
                  document.getElementById('learnaf_image').style.opacity = "1";
                }

                function learnaf_stop() {
                  document.getElementById('learnaf_image').style.opacity = "0";
                }
                learnaf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2004.12260">
                <papertitle>Learning to Autofocus</papertitle>
              </a>
              <br>
              <a href="">Charles Herrmann</a>,
              <a href="">Richard Strong Bowen</a>,
              <a href="http://nealwadhwa.com">Neal Wadhwa</a>,
              <a href="http://rahuldotgarg.appspot.com/">Rahul Garg</a>,
              <a href="https://scholar.google.com/citations?user=BxqV_RsAAAAJ">Qiurui He</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://www.cs.cornell.edu/~rdz/index.htm">Ramin Zabih</a>
              <br>
              <em>CVPR</em>, 2020  
              <br>
              <a href="https://arxiv.org/abs/2004.12260">arXiv</a>
              <p></p>
              <p>Machine learning can be used to train cameras to autofocus (which is not the same problem as "depth from defocus").</p>
            </td>
          </tr>  
          
          <tr onmouseout="porlight_stop()" onmouseover="porlight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='porlight_image'><img src='images/porlight_after.jpg'></div>
                <img src='images/porlight_before.jpg'>
              </div>
              <script type="text/javascript">
                function porlight_start() {
                  document.getElementById('porlight_image').style.opacity = "1";
                }

                function porlight_stop() {
                  document.getElementById('porlight_image').style.opacity = "0";
                }
                porlight_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1905.00824">
                <papertitle>Single Image Portrait Relighting</papertitle>
              </a>
              <br>
              <a href="http://kevinkingo.com/">Tiancheng Sun</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://ai.google/research/people/105312/">Yun-Ta Tsai</a>,
              <a href="https://cseweb.ucsd.edu/~zex014/">Zexiang Xu</a>, Xueming Yu,
              <a href="http://ict.usc.edu/profile/graham-fyffe/">Graham Fyffe</a>, Christoph Rhemann, Jay Busch,
              <a href="https://www.pauldebevec.com/">Paul Debevec</a>,
              <a href="https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>
              <br>
              <em>SIGGRAPH</em>, 2019
              <br>
              <a href="https://www.youtube.com/watch?v=yxhGWds_g4I">video</a> /
              <a href="https://petapixel.com/2019/07/16/researchers-developed-an-ai-that-can-relight-portraits-after-the-fact/">press</a> /
              <a href="data/SunSIGGRAPH2019.bib">bibtex</a>
              <br>
              <p></p>
              <p>Training a neural network on light stage scans and environment maps produces an effective relighting method.</p>
            </td>
          </tr>

          <tr onmouseout="loss_stop()" onmouseover="loss_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='loss_image'><img src='images/loss_after.png'></div>
                <img src='images/loss_before.png'>
              </div>
              <script type="text/javascript">
                function loss_start() {
                  document.getElementById('loss_image').style.opacity = "1";
                }

                function loss_stop() {
                  document.getElementById('loss_image').style.opacity = "0";
                }
                loss_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/open?id=1xpZ0fL9h1y9RfcTyPgVkxUrF3VwdkBvq">
                <papertitle>A General and Adaptive Robust Loss Function</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>
              <br>
              <em>CVPR</em>, 2019 &nbsp <font color="red"><strong>(Oral Presentation, Best Paper Award Finalist)</strong></font>
              <br>
              <a href="https://arxiv.org/abs/1701.03077">arxiv</a> /
              <a href="https://drive.google.com/open?id=1HNveL7xSNh6Ss7sxLK8Mw2L1Fc-rRhL4">supplement</a> /
              <a href="https://youtu.be/BmNKbnF69eY">video</a> /
              <a href="https://www.youtube.com/watch?v=4IInDT_S0ow&t=37m22s">talk</a> / 
              <a href="https://drive.google.com/file/d/1GzRYRIfLHvNLT_QwjHoBjHkBbs3Nbf0x/view?usp=sharing">slides</a> / 
              code: <a href="https://github.com/google-research/google-research/tree/master/robust_loss">TF</a>, <a href="https://github.com/google-research/google-research/tree/master/robust_loss_jax">JAX</a>, <a href="https://github.com/jonbarron/robust_loss_pytorch">pytorch</a> /
              <a href="data/BarronCVPR2019_reviews.txt">reviews</a> /
              <a href="data/BarronCVPR2019.bib">bibtex</a>
              <p></p>
              <p>A single robust loss function is a superset of many other common robust loss functions, and allows training to automatically adapt the robustness of its own loss.</p>
            </td>
          </tr>

          <tr onmouseout="mpi_stop()" onmouseover="mpi_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mpi_image'><img src='images/mpi_after.jpg'></div>
                <img src='images/mpi_before.jpg'>
              </div>
              <script type="text/javascript">
                function mpi_start() {
                  document.getElementById('mpi_image').style.opacity = "1";
                }

                function mpi_stop() {
                  document.getElementById('mpi_image').style.opacity = "0";
                }
                mpi_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1TU5L6fnt4Kd49IUOU7aNxor5NIgdHuNG/view?usp=sharing">
                <papertitle>Pushing the Boundaries of View Extrapolation with Multiplane Images</papertitle>
              </a>
              <br>
              <a href="https://people.eecs.berkeley.edu/~pratul/">Pratul P. Srinivasan</a>, Richard Tucker,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>,
              <a href="http://graphics.stanford.edu/~renng/">Ren Ng</a>,
              <a href="https://www.cs.cornell.edu/~snavely/">Noah Snavely</a>
              <br>
              <em>CVPR</em>, 2019 &nbsp <font color="red"><strong>(Oral Presentation, Best Paper Award Finalist)</strong></font>
              <br>
              <a href="https://drive.google.com/file/d/1GUW_n-BAn9Q4VntEA_OTHNJiHO7XfC62/view?usp=sharing">supplement</a> /
              <a href="https://www.youtube.com/watch?v=aJqAaMNL2m4">video</a> /
              <a href="data/SrinivasanCVPR2019.bib">bibtex</a>
              <p></p>
              <p>View extrapolation with multiplane images works better if you reason about disocclusions and disparity sampling frequencies.</p>
            </td>
          </tr>

          <tr onmouseout="unprocessing_stop()" onmouseover="unprocessing_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='unprocessing_image'><img src='images/unprocessing_after.jpg'></div>
                <img src='images/unprocessing_before.jpg'>
              </div>
              <script type="text/javascript">
                function unprocessing_start() {
                  document.getElementById('unprocessing_image').style.opacity = "1";
                }

                function unprocessing_stop() {
                  document.getElementById('unprocessing_image').style.opacity = "0";
                }
                unprocessing_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1H0Wtd--un2JN76dUJN8iC9fWfkA16n8D/view?usp=sharing">
                <papertitle>Unprocessing Images for Learned Raw Denoising</papertitle>
              </a>
              <br>
              <a href="http://timothybrooks.com/">Tim Brooks</a>,
              <a href="https://people.eecs.berkeley.edu/~bmild/">Ben Mildenhall</a>,
              <a href="https://people.csail.mit.edu/tfxue/">Tianfan Xue</a>,
              <a href="http://people.csail.mit.edu/jiawen/">Jiawen Chen</a>,
              <a href="http://www.dsharlet.com/">Dillon Sharlet</a>,
              <strong>Jonathan T. Barron</strong>
              <br>
              <em>CVPR</em>, 2019 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://arxiv.org/abs/1811.11127">arxiv</a> /
              <a href="http://timothybrooks.com/tech/unprocessing/">project page</a> /
              <a href="https://github.com/google-research/google-research/tree/master/unprocessing">code</a> / 
              <a href="data/BrooksCVPR2019.bib">bibtex</a>
              <p></p>
              <p>We can learn a better denoising model by processing and unprocessing images the same way a camera does.</p>
            </td>
          </tr>

          <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='motionblur_image'><img src='images/motionblur_after.jpg'></div>
                <img src='images/motionblur_before.jpg'>
              </div>
              <script type="text/javascript">
                function motionblur_start() {
                  document.getElementById('motionblur_image').style.opacity = "1";
                }

                function motionblur_stop() {
                  document.getElementById('motionblur_image').style.opacity = "0";
                }
                motionblur_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1hWpA4f6iLVcOkZI3zEAAWKARSQhnVgbY/view?usp=sharing">
                <papertitle>Learning to Synthesize Motion Blur</papertitle>
              </a>
              <br>
              <a href="http://timothybrooks.com/">Tim Brooks</a>,
              <strong>Jonathan T. Barron</strong>
              <br>
              <em>CVPR</em>, 2019 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://arxiv.org/abs/1811.11745">arxiv</a> /
              <a href="https://drive.google.com/file/d/1dUQwBMmQdYYIP0zHR_nDQY-uQbaMdcSN/view?usp=sharing">supplement</a> /
              <a href="http://timothybrooks.com/tech/motion-blur/">project page</a> /
              <a href="https://www.youtube.com/watch?v=8T1jjSz-2V8">video</a> /
              <a href="https://github.com/google-research/google-research/tree/master/motion_blur">code</a> / 
              <a href="data/BrooksBarronCVPR2019.bib">bibtex</a>
              <p></p>
              <p>Frame interpolation techniques can be used to train a network that directly synthesizes linear blur kernels.</p>
            </td>
          </tr>

          <tr onmouseout="darkflash_stop()" onmouseover="darkflash_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='darkflash_image'><img src='images/darkflash_after.png'></div>
                <img src='images/darkflash_before.png'>
              </div>
              <script type="text/javascript">
                function darkflash_start() {
                  document.getElementById('darkflash_image').style.opacity = "1";
                }

                function darkflash_stop() {
                  document.getElementById('darkflash_image').style.opacity = "0";
                }
                darkflash_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1901.01370">
                <papertitle>Stereoscopic Dark Flash for Low-light Photography</papertitle>
              </a>
              <br>
              <a href="https://www.andrew.cmu.edu/user/jianwan2/">Jian Wang</a>,
              <a href="https://people.csail.mit.edu/tfxue/">Tianfan Xue</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://people.csail.mit.edu/jiawen/">Jiawen Chen</a>
              <br>
              <em>ICCP</em>, 2019
              <br>
              <p></p>
              <p>
                By making one camera in a stereo pair hyperspectral we can multiplex dark flash pairs in space instead of time.
              </p>
            </td>
          </tr>

          <tr onmouseout="motionstereo_stop()" onmouseover="motionstereo_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='motionstereo_image'><img src='images/motionstereo_after.png'></div>
                <img src='images/motionstereo_before.png'>
              </div>
              <script type="text/javascript">
                function motionstereo_start() {
                  document.getElementById('motionstereo_image').style.opacity = "1";
                }

                function motionstereo_stop() {
                  document.getElementById('motionstereo_image').style.opacity = "0";
                }
                motionstereo_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1AABFJ3NgD5DAo5JEpEjWZrcQNzjZnvW9/view?usp=sharing">
                <papertitle>Depth from Motion for Smartphone AR</papertitle>
              </a>
              <br>
              <a href="https://www.linkedin.com/in/valentinjulien/">Julien Valentin</a>,
              <a href="https://www.linkedin.com/in/adarshkowdle/">Adarsh Kowdle</a>,
              <strong>Jonathan T. Barron</strong>, <a href="http://nealwadhwa.com">Neal Wadhwa</a>, and others
              <br>
              <em>SIGGRAPH Asia</em>, 2018
              <br>
              <a href="data/Valentin2018.bib">bibtex</a>
              <p></p>
              <p>Depth cues from camera motion allow for real-time occlusion effects in augmented reality applications.</p>
            </td>
          </tr>

          <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='portrait_image'><img src='images/portrait_after.jpg'></div>
                <img src='images/portrait_before.jpg'>
              </div>
              <script type="text/javascript">
                function portrait_start() {
                  document.getElementById('portrait_image').style.opacity = "1";
                }

                function portrait_stop() {
                  document.getElementById('portrait_image').style.opacity = "0";
                }
                portrait_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/13i6DlS9UhGVKmwslLUFnKBwdxFRVQeQj/view?usp=sharing">
                <papertitle>Synthetic Depth-of-Field with a Single-Camera Mobile Phone</papertitle>
              </a>
              <br>
              <a href="http://nealwadhwa.com">Neal Wadhwa</a>,
              <a href="http://rahuldotgarg.appspot.com/">Rahul Garg</a>,
              <a href="http://graphics.stanford.edu/~dejacobs/">David E. Jacobs</a>, Bryan E. Feldman, Nori Kanazawa, Robert Carroll,
              <a href="http://www.cs.cmu.edu/~ymovshov/">Yair Movshovitz-Attias</a>,
              <strong>Jonathan T. Barron</strong>, Yael Pritch,
              <a href="http://graphics.stanford.edu/~levoy/">Marc Levoy</a>
              <br>
              <em>SIGGRAPH</em>, 2018
              <br>
              <a href="https://arxiv.org/abs/1806.04171">arxiv</a> /
              <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">blog post</a> /
              <a href="data/Wadhwa2018.bib">bibtex</a>
              <p></p>
              <p>Dual pixel cameras and semantic segmentation algorithms can be used for shallow depth of field effects.</p>
              <p>This system is the basis for "Portrait Mode" on the Google Pixel 2 smartphones</p>
            </td>
          </tr>

          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='aperture_image'><img src='images/aperture_after.jpg'></div>
                <img src='images/aperture_before.jpg'>
              </div>
              <script type="text/javascript">
                function aperture_start() {
                  document.getElementById('aperture_image').style.opacity = "1";
                }

                function aperture_stop() {
                  document.getElementById('aperture_image').style.opacity = "0";
                }
                aperture_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1MpvxcW7OTJP321QL_q4ZLQ8D653bZZzy/view?usp=sharing">
                <papertitle>Aperture Supervision for Monocular Depth Estimation</papertitle>
              </a>
              <br>
              <a href="https://people.eecs.berkeley.edu/~pratul/">Pratul P. Srinivasan</a>,
              <a href="http://rahuldotgarg.appspot.com/">Rahul Garg</a>,
              <a href="http://nealwadhwa.com">Neal Wadhwa</a>,
              <a href="http://graphics.stanford.edu/~renng/">Ren Ng</a>,
              <strong>Jonathan T. Barron</strong>
              <br>
              <em>CVPR</em>, 2018
              <br>
              <a href="https://github.com/google/aperture_supervision">code</a> /
              <a href="data/Srinivasan2018.bib">bibtex</a>
              <p></p>
              <p>Varying a camera's aperture provides a supervisory signal that can teach a neural network to do monocular depth estimation.</p>
            </td>
          </tr>

          <tr onmouseout="deepburst_stop()" onmouseover="deepburst_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='deepburst_image'><img src='images/deepburst_after.png'></div>
                <img src='images/deepburst_before.png'>
              </div>
              <script type="text/javascript">
                function deepburst_start() {
                  document.getElementById('deepburst_image').style.opacity = "1";
                }

                function deepburst_stop() {
                  document.getElementById('deepburst_image').style.opacity = "0";
                }
                deepburst_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1GAH8ijyZ7GnoBnQFANEzdXinHrE4vvXn/view?usp=sharing">
                <papertitle>Burst Denoising with Kernel Prediction Networks</papertitle>
              </a>
              <br>
              <a href="https://people.eecs.berkeley.edu/~bmild/">Ben Mildenhall</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://people.csail.mit.edu/jiawen/">Jiawen Chen</a>,
              <a href="http://www.dsharlet.com/">Dillon Sharlet</a>,
              <a href="http://graphics.stanford.edu/~renng/">Ren Ng</a>, Robert Carroll
              <br>
              <em>CVPR</em>, 2018 &nbsp <font color=#FF8080><strong>(Spotlight)</strong></font>
              <br>
              <a href="https://drive.google.com/file/d/1aqk3Q-L2spjLZh2yRWKUWIDcZkGjQ7US/view?usp=sharing">supplement</a> /
              <a href="https://github.com/google/burst-denoising">code</a> /
              <a href="data/Mildenhall2018.bib">bibtex</a>
              <p></p>
              <p>We train a network to predict linear kernels that denoise noisy bursts from cellphone cameras.</p>
            </td>
          </tr>

          <tr onmouseout="friendly_stop()" onmouseover="friendly_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='friendly_image'><img src='images/friendly_after.png'></div>
                <img src='images/friendly_before.png'>
              </div>
              <script type="text/javascript">
                function friendly_start() {
                  document.getElementById('friendly_image').style.opacity = "1";
                }

                function friendly_stop() {
                  document.getElementById('friendly_image').style.opacity = "0";
                }
                friendly_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1w_0djhL0QgC_fbehnJ0c-J23_kW_420p/view?usp=sharing">
                <papertitle>A Hardware-Friendly Bilateral Solver for Real-Time Virtual Reality Video</papertitle>
              </a>
              <br>
              <a href="https://homes.cs.washington.edu/~amrita/">Amrita Mazumdar</a>, <a href="http://homes.cs.washington.edu/~armin/">Armin Alaghi</a>, <strong>Jonathan T. Barron</strong>, <a href="https://www.cs.unc.edu/~gallup/">David Gallup</a>, <a href="https://homes.cs.washington.edu/~luisceze/">Luis Ceze</a>, <a href="https://homes.cs.washington.edu/~oskin/">Mark Oskin</a>, <a href="http://homes.cs.washington.edu/~seitz/">Steven M. Seitz</a>
              <br>
              <em>High-Performance Graphics (HPG)</em>, 2017
              <br>
              <a href="https://sampa.cs.washington.edu/projects/vr-hw.html">project page</a>
              <p></p>
              <p>A reformulation of the bilateral solver can be implemented efficiently on GPUs and FPGAs.</p>
            </td>
          </tr>

          <tr onmouseout="hdrnet_stop()" onmouseover="hdrnet_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='hdrnet_image'><img src='images/hdrnet_after.jpg'></div>
                <img src='images/hdrnet_before.jpg'>
              </div>
              <script type="text/javascript">
                function hdrnet_start() {
                  document.getElementById('hdrnet_image').style.opacity = "1";
                }

                function hdrnet_stop() {
                  document.getElementById('hdrnet_image').style.opacity = "0";
                }
                hdrnet_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1jQY3CTMnLX7PeGUzYLso9H1eCsZyWbwg/view?usp=sharing">
                <papertitle>Deep Bilateral Learning for Real-Time Image Enhancement</papertitle>
              </a>
              <br>
              <a href="http://www.mgharbi.com">Micha&euml;l Gharbi</a>, <a href="http://people.csail.mit.edu/jiawen/">Jiawen Chen</a>, <strong>Jonathan T. Barron</strong>, <a href="https://people.csail.mit.edu/hasinoff/">Samuel W. Hasinoff</a>, <a href="http://people.csail.mit.edu/fredo/">Fr&eacute;do Durand </a>
              <br>
              <em>SIGGRAPH</em>, 2017
              <br>
              <a href="https://groups.csail.mit.edu/graphics/hdrnet/">project page</a> /
              <a href="https://www.youtube.com/watch?v=GAe0qKKQY_I">video</a> /
              <a href="data/GharbiSIGGRAPH2017.bib">bibtex</a> /
              <a href="http://news.mit.edu/2017/automatic-image-retouching-phone-0802">p</a><a href="https://www.wired.com/story/googles-new-algorithm-perfects-photos-before-you-even-take-them/">r</a><a href="https://petapixel.com/2017/08/02/new-ai-can-retouch-photos-snap/">e</a><a href="https://www.theverge.com/2017/8/2/16082272/google-mit-retouch-photos-machine-learning">s</a><a href="http://gizmodo.com/clever-camera-app-uses-deep-learning-to-perfectly-retou-1797474282">s</a>
              <p></p>
              <p>By training a deep network in bilateral space we can learn a model for high-resolution and real-time image enhancement.</p>
            </td>
          </tr>

          <tr onmouseout="ffcc_stop()" onmouseover="ffcc_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ffcc_image'><img src='images/ffcc_after.jpg'></div>
                <img src='images/ffcc_before.jpg'>
              </div>
              <script type="text/javascript">
                function ffcc_start() {
                  document.getElementById('ffcc_image').style.opacity = "1";
                }

                function ffcc_stop() {
                  document.getElementById('ffcc_image').style.opacity = "0";
                }
                ffcc_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1611.07596">
                <papertitle>Fast Fourier Color Constancy</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>,
              <a href="https://ai.google/research/people/105312/">Yun-Ta Tsai</a>,
              <br>
              <em>CVPR</em>, 2017
              <br>
              <a href="https://youtu.be/rZCXSfl13rY">video</a> /
              <a href="data/BarronTsaiCVPR2017.bib">bibtex</a> /
              <a href="https://github.com/google/ffcc">code</a> /
              <a href="https://drive.google.com/open?id=0B4nuwEMaEsnmWkJQMlFPSFNzbEk">output</a> /
              <a href="https://blog.google/products/photos/six-tips-make-your-photos-pop/">blog post</a> /
              <a href="https://9to5google.com/2017/03/03/google-photos-auto-white-balance/">p</a><a href="https://www.engadget.com/2017/03/03/google-photos-automatically-fixes-your-pictures-white-balance/">r</a><a href="https://lifehacker.com/google-photos-will-now-automatically-adjust-the-white-b-1793009155">e</a><a href="https://petapixel.com/2017/03/06/google-photos-will-now-automatically-white-balance-snapshots/">s</a><a href="http://www.theverge.com/2017/3/3/14800062/google-photos-auto-white-balance-android">s</a>
              <p></p>
              <p>Color space can be aliased, allowing white balance models to be learned and evaluated in the frequency domain. This improves accuracy by 13-20% and speed by 250-3000x.</p>
              <p>This technology is used by <a href="https://store.google.com/product/pixel_compare">Google Pixel</a>, <a href="https://photos.google.com/">Google Photos</a>, and <a href="https://www.google.com/maps">Google Maps</a>.</p>
            </td>
          </tr>
		
          <tr onmouseout="bs_stop()" onmouseover="bs_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='bs_image'><img src='images/BS_after.jpg'></div>
                <img src='images/BS_before.jpg'>
              </div>
              <script type="text/javascript">
                function bs_start() {
                  document.getElementById('bs_image').style.opacity = "1";
                }

                function bs_stop() {
                  document.getElementById('bs_image').style.opacity = "0";
                }
                bs_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1zFzCaFwkGK1EGmJ_KEqb-ZsRJhfUKN2S/view?usp=sharing">
                <papertitle>The Fast Bilateral Solver</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>,
              <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>
              <br>
              <em>ECCV</em>, 2016 &nbsp <font color="red"><strong>(Oral Presentation, Best Paper Honorable Mention)</strong></font>
              <br>
              <a href="http://arxiv.org/abs/1511.03296">arXiv</a> /
              <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmdEREcjhlSXM2NGs/view?usp=sharing">supplement</a> /
              <a href="data/BarronPooleECCV2016.bib">bibtex</a> /
              <a href="http://videolectures.net/eccv2016_barron_bilateral_solver/">video (they messed up my slides, use &rarr;)</a> /
              <a href="https://drive.google.com/file/d/19x1AeN0PFus6Pjrd8nR-vCmJ6bNEefsC/view?usp=sharing">keynote</a> (or <a href="https://drive.google.com/file/d/1p9nduiymK9jUh7WfwlsMjBfW8RoNe_61/view?usp=sharing">PDF</a>) /
              <a href="https://github.com/poolio/bilateral_solver">code</a> /
              <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmaDI3bm5VeDRxams/view?usp=sharing">depth super-res results</a> /
              <a href="data/BarronPooleECCV2016_reviews.txt">reviews</a>
              <p></p>
              <p>Our solver smooths things better than other filters and faster than other optimization algorithms, and you can backprop through it.</p>
            </td>
          </tr>

          <tr onmouseout="diverdi_stop()" onmouseover="diverdi_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='diverdi_image'><img src='images/diverdi_after.jpg'></div>
                <img src='images/diverdi_before.jpg'>
              </div>
              <script type="text/javascript">
                function diverdi_start() {
                  document.getElementById('diverdi_image').style.opacity = "1";
                }

                function diverdi_stop() {
                  document.getElementById('diverdi_image').style.opacity = "0";
                }
                diverdi_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1mmT-LuK_eBZsl3qp4-fAshEPdgfbgvNE/view?usp=sharing">
                <papertitle>Geometric Calibration for Mobile, Stereo, Autofocus Cameras</papertitle>
              </a>
              <br>
              <a href="http://www.stephendiverdi.com/">Stephen DiVerdi</a>,
              <strong>Jonathan T. Barron</strong>
              <br>
              <em>WACV</em>, 2016
              <br>
              <a href="data/Diverdi2016.bib">bibtex</a>
              <p></p>
              <p>Standard techniques for stereo calibration don't work for cheap mobile cameras.</p>
            </td>
          </tr>

          <tr onmouseout="dt_stop()" onmouseover="dt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dt_image'><img src='images/DT_edge.jpg'></div>
                <img src='images/DT_image.jpg'>
              </div>
              <script type="text/javascript">
                function dt_start() {
                  document.getElementById('dt_image').style.opacity = "1";
                }

                function dt_stop() {
                  document.getElementById('dt_image').style.opacity = "0";
                }
                dt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/178Xj2PZ1w6hZJpucU-TiZOoCemJmvsVQ/view?usp=sharing">
                <papertitle>Semantic Image Segmentation with Task-Specific Edge Detection Using CNNs and a Discriminatively Trained Domain Transform</papertitle>
              </a>
              <br>
              <em>CVPR</em>, 2016
              <br>
              <a href="http://liangchiehchen.com/">Liang-Chieh Chen</a>, <strong>Jonathan T. Barron</strong>, <a href="http://ttic.uchicago.edu/~gpapan/">George Papandreou</a>, <a href="http://www.cs.ubc.ca/~murphyk/">Kevin Murphy</a>, <a href="http://www.stat.ucla.edu/~yuille/">Alan L. Yuille</a>
              <br>
              <a href="data/Chen2016.bib">bibtex</a> /
              <a href="http://liangchiehchen.com/projects/DeepLab.html">project page</a> /
              <a href="https://bitbucket.org/aquariusjay/deeplab-public-ver2">code</a>
              <p></p>
              <p>By integrating an edge-aware filter into a convolutional neural network we can learn an edge-detector while improving semantic segmentation.</p>
            </td>
          </tr>

          <tr onmouseout="ccc_stop()" onmouseover="ccc_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ccc_image'><img src='images/ccc_after.jpg'></div>
                <img src='images/ccc_before.jpg'>
              </div>
              <script type="text/javascript">
                function ccc_start() {
                  document.getElementById('ccc_image').style.opacity = "1";
                }

                function ccc_stop() {
                  document.getElementById('ccc_image').style.opacity = "0";
                }
                ccc_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1id74VNDL8ACrrWf6vYgN2M4kS8gd4n7w/view?usp=sharing">
                <papertitle>Convolutional Color Constancy</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>
              <br>
              <em>ICCV</em>, 2015
              <br>
              <a href="https://drive.google.com/file/d/1vO3sVOMihmpNqsuASeR46Y_iME0lOANR/view?usp=sharing">supplement</a> / <a href="data/BarronICCV2015.bib">bibtex</a> / <a href="https://youtu.be/saHwKY9rfx0">video</a> (or <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmalBNUzlENUJSVDg/view?usp=sharing">mp4</a>)
              <p></p>
              <p>By framing white balance as a chroma localization task we can discriminatively learn a color constancy model that beats the state-of-the-art by 40%.</p>
            </td>
          </tr>


        </tbody></table>
	
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Patents</heading>
        </td>
        </tr>
        </tbody></table>
		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	  <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='projects/ICdetection_image2.JPG' width="160">
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9227159">
                <papertitle>Methods and systems of path-based mapping and routing</papertitle>
              </a>
              <br>
		3M Innovative Properties Company, 3M Company
              <br>
              <a href="https://kaurrachneet6.github.io/projects/virtual_reality_bookchapter">Patent page</a> |
              <a href="https://investors.3m.com/news/news-details/2017/3M-Completes-Acquisition-of-Scott-Safety-Business-Enhances-Personal-Safety-Offering/default.aspx#:~:text=3M%20Completes%20Acquisition%20of%20Scott%20Safety%3B%20Business%20Enhances%20Personal%20Safety%20Offering,-October%204%2C%202017&text=ST.,enterprise%20value%20of%20%242.0%20billion%20.">Project background</a> |
              <a href="./Data/VRchapter.bib">Cite</a>
              <p></p>
              <p>XXX Add description XXX</p>
            </td>
          </tr> 
	</tbody></table>
	
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Book chapters</heading>
        </td>
        </tr>
        </tbody></table>    
	
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	  <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='projects/ICdetection_image2.JPG' width="160">
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9227159">
                <papertitle>Virtual Reality and Movement Disorders</papertitle>
              </a>
              <br>
		  <strong>Rachneet Kaur</strong>,
		  <a href="https://ahs.illinois.edu/hernandez">Manuel Hernandez</a>,
		  <a href="https://ise.illinois.edu/directory/profile/r-sowers">Richard Sowers</a>
              <br>
              Virtual Reality: Recent Advancements, Applications and Challenges, River Publishers, 2020
              <br>
              <a href="https://kaurrachneet6.github.io/projects/virtual_reality_bookchapter">Project page</a> |
              <a href="https://ieeexplore.ieee.org/document/9227159">Chapter</a> |
              <a href="https://ieeexplore.ieee.org/book/9218881">Book</a> |
              <a href="./Data/VRchapter.bib">Cite (chapter)</a> |
              <a href="./Data/Virtual_Reality_Book.bibtex">Cite (book)</a>
              <p></p>
              <p>XXX Add description XXX</p>
            </td>
          </tr> 
	</tbody></table>
	
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Posters and Talks</heading>
        </td>
        </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Projects</heading>
        </td>
        </tr>
        </tbody></table>
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Service</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
              <br>
              <br>
              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cs188.jpg" alt="cs188">
            </td>
            <td width="75%" valign="center">
              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
              <br>
              <br>
              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
              <br>
              <br>
              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
            </td>
          </tr>
        </tbody></table>
                
         
	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Collaborations and Mentorship</heading>
            </td>
          </tr>
        </tbody></table>
	
	<p>At UIUC, I have had a chance to work with and mentor some excellent students:</p>
	<table width="100%" align="left" border="0" cellpadding="5"><tbody>
	<tr>
	<td width="100%" valign="center" style="padding-left:20px">
	&bull; <a href="https://www.linkedin.com/in/daanmichiels/?originalSubdomain=uk"> Daan Michiels</a> (Currently Senior Quantitative Researcher at G-Research)
	<br>
	&bull; <a href="https://www.linkedin.com/in/vivek-kaushik-62199010a/"> Vivek Kaushik</a> (Currently PhD candidate at the Department of Mathematics, UIUC)
	<br>
	&bull; <a href="https://www.linkedin.com/in/yankun-zhao-415b57152/"> Yankun Zhao</a> (Currently MS in Computer Science candidate at Yale University)
	<br>
	&bull; <a href="https://www.linkedin.com/in/zhonghao-dennis-zhao-967055135/"> Zhonghao (Dennis) Zhao</a> (Currently MS in Analytics candidate at Northwestern University)
	<br>	
	&bull; <a href="https://www.linkedin.com/in/maxim-korolkov-04004bb5/"> Maxim Korolkov</a>
	<br>
	&bull; <a href="malto:rk4@illinois.edu"> Zizhang Chen</a>
	<br>
	</td>
	</tr>
	</tbody></table>
	
	
	
	
         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Contact Me</heading>
            </td>
          </tr>
        </tbody></table>
        
          <table width="55%" align="left" border="0" cellpadding="5"><tbody>
          <tr>
            <td style="padding:1px;width:15%;max-width:50%;height:5%;max-height:5%;vertical-align:center"><img src="Images/location.png" width = "75"></td>
            <td width="85%" valign="center">
              Room 205, Transportation building, <br>University of Illinois at Urbana-Champaign
            </td>
          </tr>
          <tr>
            <td style="padding:1px;width:15%;height:1%;vertical-align:left">
              <img src="Images/email.png" alt="Email" width = "75">
            </td>
            <td width="85%" valign="center">
              <a href="malto:rk4@illinois.edu">rk4@illinois.edu</a>
              <br>
              <a href="mailto:kaurrachneet6@gmail.com">kaurrachneet6@gmail.com</a>
            </td>
          </tr>
        </tbody></table>
        
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <br>
                Template credits: <a href="https://jonbarron.info/">Joe</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
